{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigrams \n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk.tag.stanford as ST\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1..........# creating bigram for negatives\n",
    "\n",
    "f = open(\"combinedNEG.txt\")\n",
    "raw_f = f.read()\n",
    "\n",
    "tokens = raw_f.split()\n",
    "#print(tokens)\n",
    "\n",
    "\n",
    "# creation of bigrams\n",
    "bgs = nltk.bigrams(tokens)\n",
    "\n",
    "#compute frequency\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "sorted_words = sorted(fdist.items(),key= lambda x:x[1], reverse = True)\n",
    "\n",
    "output_file = open(\"out_bigram_Uncleaned.txt\",\"w\")\n",
    "\n",
    "\n",
    "\n",
    "for k,v in sorted_words:\n",
    "    bi_word =(k[0]+\"_\"+k[1]+\" \"+str(v) +\"\\n\")\n",
    "    output_file.write(bi_word)\n",
    "output_file.close()\n",
    "\n",
    "\n",
    "### bigrams probabilities\n",
    "\n",
    "words_f = [i for i in raw_f.split()]\n",
    "uny_f=[]\n",
    "unique_words = set(words_f)\n",
    "for word in unique_words:\n",
    "    uny_f.append(str(word))\n",
    "#print(uny_f)\n",
    "#len(uny_f)\n",
    "\n",
    "neg_list ={}\n",
    "\n",
    "for word in uny_f:\n",
    "    neg_count = 0\n",
    "    for word1 in words_f:\n",
    "        if word1==word:\n",
    "            neg_count = neg_count+1\n",
    "    neg_list[word] = (neg_count)\n",
    "#print(neg_list)\n",
    "\n",
    "#output_file1 = open(\"out_bigram_Uncleaned_pro.txt\",\"w\")\n",
    "\n",
    "\n",
    "neg_biag = []\n",
    "\n",
    "for k,v in sorted_words:\n",
    "    v = v/(neg_list[k[0]])\n",
    "    bi_word =(k[0]+\" \"+k[1]+\" \"+str(v))\n",
    "    neg_biag.append(bi_word)\n",
    "#output_file1.close()\n",
    "\n",
    "\n",
    "#f1 = open(\"out_bigram_Uncleaned_pro.txt\")\n",
    "#raw_f1 = f1.read()\n",
    "#f2 = raw_f1.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2............# creating bigrams for neutral\n",
    "\n",
    "g = open(\"combinedNEU.txt\")\n",
    "raw_g = g.read()\n",
    "\n",
    "tokens = raw_g.split()\n",
    "#print(tokens)\n",
    "\n",
    "\n",
    "# creation of bigrams\n",
    "bgs = nltk.bigrams(tokens)\n",
    "\n",
    "#compute frequency\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "sorted_words = sorted(fdist.items(),key= lambda x:x[1], reverse = True)\n",
    "\n",
    "#output_file = open(\"out_bigram_Uncleaned.txt\",\"w\")\n",
    "\n",
    "\n",
    "\n",
    "# redundant routine. Was there earlier also. Not required\n",
    "\n",
    "#for k,v in sorted_words:\n",
    " #   bi_word =(k[0]+\"_\"+k[1]+\" \"+str(v) +\"\\n\")\n",
    "  #  output_file.write(bi_word)\n",
    "#output_file.close()\n",
    "\n",
    "\n",
    "### bigrams probabilities\n",
    "\n",
    "words_g = [i for i in raw_g.split()]\n",
    "uny_g=[]\n",
    "unique_words = set(words_g)\n",
    "for word in unique_words:\n",
    "    uny_g.append(str(word))\n",
    "#print(uny_f)\n",
    "#len(uny_f)\n",
    "\n",
    "neu_list ={}\n",
    "\n",
    "for word in uny_g:\n",
    "    neu_count = 0\n",
    "    for word1 in words_g:\n",
    "        if word1==word:\n",
    "            neu_count = neu_count+1\n",
    "    neu_list[word] = (neu_count)\n",
    "#print(neg_list)\n",
    "\n",
    "#output_file1 = open(\"out_bigram_Uncleaned_pro.txt\",\"w\")\n",
    "\n",
    "\n",
    "neu_biag = []\n",
    "\n",
    "for k,v in sorted_words:\n",
    "    v = v/(neu_list[k[0]])\n",
    "    bi_word =(k[0]+\" \"+k[1]+\" \"+str(v))\n",
    "    neu_biag.append(bi_word)\n",
    "#output_file1.close()\n",
    "\n",
    "\n",
    "#f1 = open(\"out_bigram_Uncleaned_pro.txt\")\n",
    "#raw_f1 = f1.read()\n",
    "#f2 = raw_f1.splitlines()\n",
    "\n",
    "\n",
    "#neu_biag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3............# creating bigrams for positive\n",
    "\n",
    "h = open(\"combinedPOS.txt\")\n",
    "raw_h = h.read()\n",
    "\n",
    "tokens = raw_h.split()\n",
    "#print(tokens)\n",
    "\n",
    "\n",
    "# creation of bigrams\n",
    "bgs = nltk.bigrams(tokens)\n",
    "\n",
    "#compute frequency\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "sorted_words = sorted(fdist.items(),key= lambda x:x[1], reverse = True)\n",
    "\n",
    "#output_file = open(\"out_bigram_Uncleaned.txt\",\"w\")\n",
    "\n",
    "\n",
    "\n",
    "# redundant routine. Was there earlier also. Not required\n",
    "\n",
    "#for k,v in sorted_words:\n",
    " #   bi_word =(k[0]+\"_\"+k[1]+\" \"+str(v) +\"\\n\")\n",
    "  #  output_file.write(bi_word)\n",
    "#output_file.close()\n",
    "\n",
    "\n",
    "### bigrams probabilities\n",
    "\n",
    "words_h = [i for i in raw_h.split()]\n",
    "uny_h=[]\n",
    "unique_words = set(words_h)\n",
    "for word in unique_words:\n",
    "    uny_h.append(str(word))\n",
    "#print(uny_f)\n",
    "#len(uny_f)\n",
    "\n",
    "pos_list ={}\n",
    "\n",
    "for word in uny_h:\n",
    "    pos_count = 0\n",
    "    for word1 in words_h:\n",
    "        if word1==word:\n",
    "            pos_count = pos_count+1\n",
    "    pos_list[word] = (pos_count)\n",
    "#print(neg_list)\n",
    "\n",
    "#output_file1 = open(\"out_bigram_Uncleaned_pro.txt\",\"w\")\n",
    "\n",
    "\n",
    "pos_biag = []\n",
    "\n",
    "for k,v in sorted_words:\n",
    "    v = v/(pos_list[k[0]])\n",
    "    bi_word =(k[0]+\" \"+k[1]+\" \"+str(v))\n",
    "    pos_biag.append(bi_word)\n",
    "#output_file1.close()\n",
    "\n",
    "\n",
    "#f1 = open(\"out_bigram_Uncleaned_pro.txt\")\n",
    "#raw_f1 = f1.read()\n",
    "#f2 = raw_f1.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [1, 2], [2, 3]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = [[]]\n",
    "op.append([1,2])\n",
    "op.append([2,3])\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# functions\n",
    "\n",
    "def testnegative(raw):\n",
    "    \n",
    "    i11    = raw\n",
    "\n",
    "    #print(i11)\n",
    "    tokens = i11.split()\n",
    "    #print(tokens)\n",
    "    bgs2 = [bigram for bigram in nltk.bigrams(tokens)]\n",
    "    bgs4 = []\n",
    "    for i in range(0,len(bgs2)):\n",
    "        bi_word = (bgs2[i][0]+\" \"+bgs2[i][1])\n",
    "        bgs4.append(bi_word)\n",
    "    \n",
    "    maxprob = 0\n",
    "    for i in bgs4:\n",
    "        j = i.split()\n",
    "        for i in neg_biag:\n",
    "            m = i.split()\n",
    "            if(m[0]==j[0] and m[1]==j[1]):\n",
    "                if(maxprob < float(m[2])):\n",
    "                    maxprob = float(m[2])\n",
    "\n",
    "    return(maxprob)\n",
    "        \n",
    "    \n",
    "def testneutral(raw):\n",
    "    \n",
    "    i11    = raw\n",
    "\n",
    "    #print(i11)\n",
    "    tokens = i11.split()\n",
    "    #print(tokens)\n",
    "    bgs2 = [bigram for bigram in nltk.bigrams(tokens)]\n",
    "    bgs4 = []\n",
    "    for i in range(0,len(bgs2)):\n",
    "        bi_word = (bgs2[i][0]+\" \"+bgs2[i][1])\n",
    "        bgs4.append(bi_word)\n",
    "    \n",
    "    maxprob = 0\n",
    "    for i in bgs4:\n",
    "        j = i.split()\n",
    "        for i in neu_biag:\n",
    "            m = i.split()\n",
    "            if(m[0]==j[0] and m[1]==j[1]):\n",
    "                if(maxprob < float(m[2])):\n",
    "                    maxprob = float(m[2])\n",
    "\n",
    "    return(maxprob)\n",
    "    \n",
    "\n",
    "def testpositive(raw):\n",
    "    \n",
    "    i11    = raw\n",
    "\n",
    "    #print(i11)\n",
    "    tokens = i11.split()\n",
    "    #print(tokens)\n",
    "    bgs2 = [bigram for bigram in nltk.bigrams(tokens)]\n",
    "    bgs4 = []\n",
    "    for i in range(0,len(bgs2)):\n",
    "        bi_word = (bgs2[i][0]+\" \"+bgs2[i][1])\n",
    "        bgs4.append(bi_word)\n",
    "    \n",
    "    maxprob = 0\n",
    "    for i in bgs4:\n",
    "        j = i.split()\n",
    "        for i in pos_biag:\n",
    "            m = i.split()\n",
    "            if(m[0]==j[0] and m[1]==j[1]):\n",
    "                if(maxprob < float(m[2])):\n",
    "                    maxprob = float(m[2])\n",
    "\n",
    "    return(maxprob)\n",
    "\n",
    "\n",
    "\n",
    "def checkdoc(raw):\n",
    "    op_list = [[]]\n",
    "    for i in raw:\n",
    "        a = testnegative(i)\n",
    "        b = testneutral(i)\n",
    "        c = testpositive(i)\n",
    "        d = max(a,b,c)\n",
    "        if (d == a):\n",
    "            op_list.append([i,\"negative\"])\n",
    "        elif(d == b):\n",
    "            op_list.append([i,\"neutral\"])\n",
    "        else:\n",
    "            op_list.append([i,\"positive\"])\n",
    "    return(op_list)\n",
    "    \n",
    "\n",
    "\n",
    "def finalreport(oplist):\n",
    "    listop = []\n",
    "    neg = 0\n",
    "    neu = 0\n",
    "    pos = 0\n",
    "    for i in range(1,len(oplist)):\n",
    "        if(oplist[i][1]==\"negative\"):\n",
    "            neg = neg+1\n",
    "        if(oplist[i][1]==\"neutral\"):\n",
    "            neu = neu+1\n",
    "        if(oplist[i][1]==\"positive\"):\n",
    "            pos = pos+1\n",
    "    listop.append([\"negative\",neg])\n",
    "    listop.append([\"neutral\",neu])\n",
    "    listop.append([\"positive\",pos])\n",
    "    return(listop)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing for negative sentiments\n",
    "\n",
    "i = open(\"testneg.txt\")\n",
    "raw_i= i.read()\n",
    "raw_i1 = raw_i.splitlines()\n",
    "\n",
    "out1 = checkdoc(raw_i1)\n",
    "\n",
    "j = open(\"testneutral.txt\")\n",
    "raw_i= j.read()\n",
    "raw_i1 = raw_i.splitlines()\n",
    "\n",
    "out2 = checkdoc(raw_i1)\n",
    "\n",
    "k = open(\"testneutral.txt\")\n",
    "raw_i= k.read()\n",
    "raw_i1 = raw_i.splitlines()\n",
    "\n",
    "out3 = checkdoc(raw_i1)\n",
    "\n",
    "\n",
    "\n",
    "#out1[0][1]\n",
    "#out1\n",
    "#negdoc = finalreport(out1)\n",
    "#negdoc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op for negative doc is [['negative', 33], ['neutral', 20], ['positive', 22]]\n",
      "op for neutral doc is [['negative', 12], ['neutral', 1], ['positive', 10]]\n",
      "op for positive doc is [['negative', 12], ['neutral', 1], ['positive', 10]]\n"
     ]
    }
   ],
   "source": [
    "#out1[1][2]\n",
    "#out1[3][1]\n",
    "#out1\n",
    "negdoc = finalreport(out1)\n",
    "#negdoc\n",
    "neudoc = finalreport(out2)\n",
    "posdoc = finalreport(out3)\n",
    "\n",
    "print(\"op for negative doc is\",negdoc)\n",
    "print(\"op for neutral doc is\",neudoc)\n",
    "print(\"op for positive doc is\",posdoc)\n",
    "#print(len(out1))\n",
    "#out1\n",
    "#for i in range(1,len(out1)):\n",
    "    #print(out1[i][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
